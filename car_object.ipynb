{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cc6c30-b46b-4a4a-87a4-e8a18a174d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Python modules successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from qarpo.demoutils import liveQstat, progressIndicator, summaryPlot, videoHTML\n",
    "from qarpo.model_visualizer_link import showModelVisualizerLink\n",
    "\n",
    "print(\"Imported Python modules successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7a470-2bcb-4f83-a2bf-d8ac5fcc06de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609b5fbe-c3ce-4bcb-a0fe-a9fb8925be44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/2023.0/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/u191360/car_object_detection/models/mobilenet-ssd/FP16/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u191360/car_object_detection/models/mobilenet-ssd/FP16/mobilenet-ssd.bin\n",
      "[ INFO ] Generated IR will be compressed to FP16. If you get lower accuracy, please consider disabling compression explicitly by adding argument --compress_to_fp16=False.\n",
      "Find more information about compression to FP16 at https://docs.openvino.ai/2023.0/openvino_docs_MO_DG_FP16_Compression.html\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/2023.0/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/u191360/car_object_detection/models/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u191360/car_object_detection/models/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "\\nAll IR files that were created:\n",
      "./models/mobilenet-ssd/FP16/mobilenet-ssd.bin\n",
      "./models/mobilenet-ssd/FP16/mobilenet-ssd.xml\n",
      "./models/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "./models/mobilenet-ssd/FP32/mobilenet-ssd.xml\n"
     ]
    }
   ],
   "source": [
    "# Create FP16 IR files\n",
    "!mo \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--compress_to_fp16   \\\n",
    "--output_dir models/mobilenet-ssd/FP16 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] \n",
    "\n",
    "# Create FP32 IR files\n",
    "!mo \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--output_dir models/mobilenet-ssd/FP32 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] \n",
    "\n",
    "# find all resulting IR files\n",
    "!echo \"\\nAll IR files that were created:\"\n",
    "!find ./models -name \"*.xml\" -o -name \"*.bin\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8e8b46-68e1-4764-a188-0d6eb58fadf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Cars Video</h2>\n",
       "    \n",
       "    <video alt=\"\" controls autoplay muted height=\"480\"><source src=\"./cars_1900.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qarpo.demoutils import videoHTML\n",
    "\n",
    "# create link and adjust video path to be able to display from /data using videoHTML()\n",
    "!ln -sfn /data data\n",
    "videoHTML(\n",
    "    \"Cars Video\", [\"./cars_1900.mp4\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9a88a0e-03fe-4c4d-b447-3197c09fea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting object_detection_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile object_detection_job.sh\n",
    "\n",
    "# Store input arguments: <output_directory> <device> <fp_precision> <input_file> <num_reqs>\n",
    "OUTPUT_FILE=$1\n",
    "DEVICE=$2\n",
    "FP_MODEL=$3\n",
    "INPUT_FILE=$4\n",
    "NUM_REQS=$5\n",
    "\n",
    "echo VENV_PATH=$VENV_PATH\n",
    "echo INPUT_FILE=$INPUT_FILE\n",
    "echo FP_MODEL=$FP_MODEL\n",
    "echo INPUT_TILE=$INPUT_FILE\n",
    "echo NUM_REQS=$NUM_REQS\n",
    "\n",
    "# Follow this order of setting up environment for openVINO 2022.1.0.553\n",
    "echo \"Activating a Python virtual environment from ${VENV_PATH}...\"\n",
    "source ${VENV_PATH}/bin/activate\n",
    "\n",
    "# The default path for the job is the user's home directory,\n",
    "#  change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# Make sure that the output directory exists.\n",
    "mkdir -p $OUTPUT_FILE\n",
    "\n",
    "# Set inference model IR files using specified precision\n",
    "MODELPATH=models/mobilenet-ssd/${FP_MODEL}/mobilenet-ssd.xml\n",
    "LABEL_FILE=./labels.txt\n",
    "\n",
    "# Run the object detection code\n",
    "python3 object_detection.py -m $MODELPATH \\\n",
    "                            -i $INPUT_FILE \\\n",
    "                            -o $OUTPUT_FILE \\\n",
    "                            -d $DEVICE \\\n",
    "                            -nireq $NUM_REQS \\\n",
    "                            --labels $LABEL_FILE\n",
    "\n",
    "# Run the output video annotator code\n",
    "SCALE_FRAME_RATE=1    # scale number or output frames to input frames\n",
    "SCALE_RESOLUTION=0.5  # scale output frame resolution \n",
    "python3 object_detection_annotate.py -i $INPUT_FILE \\\n",
    "                                     -o $OUTPUT_FILE \\\n",
    "                                     -f $SCALE_FRAME_RATE \\\n",
    "                                     -s $SCALE_RESOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e42671-5959-415e-9011-7dbd8d5621ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f0fa591a4c4042a223cdd4840fa0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='Target node'), Select(layout=Layout(width='auto'), options=('Select…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7395fce050e4bf496a832fca1a4fcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b0f341d85848a5ac2f4bbf81e63db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='No jobs submitted yet'), Tab(), Button(button_style='info', description='Plot resul…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import json\n",
    "\n",
    "import qarpo\n",
    "\n",
    "# load job configurations for demo\n",
    "with open(\"./job_config.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# create and run the user job interface\n",
    "job_interface = qarpo.Interface(data)\n",
    "job_interface.displayUI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d4071-89ac-4f8a-af01-14c99a816aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (OpenVINO 2023.1.0 Latest)",
   "language": "python",
   "name": "openvino_2023.1.0_python3.10_tf2.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
